{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "\n",
        "zip_path = \"/content/conllu.zip\"  # adjust if you used a different name\n",
        "extract_path = \"/content/conllu\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"✅ Files extracted to:\", extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_m-TRM0AseA",
        "outputId": "023f70e3-d38a-46ae-a528-da25460909f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Files extracted to: /content/conllu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "CONLLU_ROOT = \"conllu/conllu_file\"\n",
        "OUT_CSV = \"conllu/adjectives_appraisal_with_examples_by_class.csv\"\n",
        "KEEP_TOP_N = 20            # top-N adjectives per (lang, discipline) by total count\n",
        "EXAMPLES_PER_CLASS = 5     # how many example sentences to keep per classification\n",
        "# ---------- end CONFIG ----------\n",
        "\n",
        "# Patterns / heuristics\n",
        "# Patterns / heuristics\n",
        "FIRST_PERSON = {\n",
        "    # Subject + Object\n",
        "    \"i\", \"me\", \"we\", \"us\",\n",
        "    # Possessive determiners\n",
        "    \"my\", \"our\",\n",
        "    # Possessive pronouns\n",
        "    \"mine\", \"ours\",\n",
        "    # Reflexives\n",
        "    \"myself\", \"ourselves\"\n",
        "}\n",
        "\n",
        "# Second-person pronouns (for completeness — often neutral)\n",
        "SECOND_PERSON = {\n",
        "    \"you\",\n",
        "    # Possessive determiners\n",
        "    \"your\",\n",
        "    # Possessive pronouns\n",
        "    \"yours\",\n",
        "    # Reflexives\n",
        "    \"yourself\", \"yourselves\"\n",
        "}\n",
        "\n",
        "APPRECIATION_PRONOUNS = {\n",
        "    # Core expletive / dummy subject\n",
        "    \"it\", \"there\", \"here\",\n",
        "\n",
        "    # Demonstratives (singular/plural)\n",
        "    \"this\", \"that\", \"these\", \"those\",\n",
        "\n",
        "    # Indefinites referring to things/objects\n",
        "    \"something\", \"anything\", \"nothing\", \"everything\",\n",
        "    \"someone\", \"anyone\", \"no one\", \"everyone\",\n",
        "    \"somebody\", \"anybody\", \"nobody\", \"everybody\",\n",
        "\n",
        "    # Quantified / abstract pronouns\n",
        "    \"all\", \"each\", \"both\", \"neither\", \"none\", \"one\",\n",
        "\n",
        "    # Wh-pronouns often referring to things\n",
        "    \"what\", \"whatever\", \"which\", \"whichever\",\n",
        "\n",
        "    # Event-like references (treated as abstract appreciation subjects)\n",
        "    \"this one\", \"that one\", \"such\", \"so\"\n",
        "}\n",
        "\n",
        "FEEL_VERBS = {\n",
        "    # Core copular / linking\n",
        "    \"be\", \"become\", \"get\", \"remain\", \"stay\", \"keep\", \"prove\", \"turn\",\n",
        "\n",
        "    # Seem / appear / perception-of-truth\n",
        "    \"seem\", \"appear\", \"sound\", \"look\", \"smell\", \"taste\", \"feel\",\n",
        "\n",
        "    # Evaluation / cognition (mental stance)\n",
        "    \"think\", \"consider\", \"believe\", \"find\", \"judge\", \"deem\", \"regard\", \"suppose\",\n",
        "    \"reckon\", \"assume\", \"imagine\", \"guess\", \"suspect\", \"presume\", \"conclude\",\n",
        "\n",
        "    # Communication verbs that take complements\n",
        "    \"say\", \"claim\", \"argue\", \"maintain\", \"suggest\", \"assert\", \"contend\", \"report\",\n",
        "\n",
        "    # Desire / volition\n",
        "    \"want\", \"wish\", \"hope\", \"long\", \"yearn\", \"desire\", \"prefer\", \"intend\", \"plan\",\n",
        "    \"aim\", \"aspire\",\n",
        "\n",
        "    # Liking / disliking / attitude\n",
        "    \"like\", \"love\", \"enjoy\", \"admire\", \"appreciate\", \"cherish\", \"favor\", \"fancy\",\n",
        "    \"care\", \"mind\",\n",
        "    \"dislike\", \"hate\", \"detest\", \"despise\", \"loathe\", \"resent\", \"scorn\", \"disdain\",\n",
        "\n",
        "    # Emotional / affective\n",
        "    \"fear\", \"dread\", \"regret\", \"worry\", \"doubt\", \"mourn\", \"lament\", \"envy\", \"pity\",\n",
        "    \"sympathize\", \"empathize\", \"applaud\", \"praise\", \"criticize\", \"blame\", \"condemn\",\n",
        "\n",
        "    # Modal / necessity / obligation\n",
        "    \"must\", \"should\", \"ought\", \"need\", \"have_to\", \"require\", \"demand\", \"deserve\",\n",
        "\n",
        "    # Experiential / perception\n",
        "    \"watch\", \"observe\", \"notice\", \"perceive\", \"recognize\", \"detect\", \"spot\",\n",
        "\n",
        "    # Misc. evaluative\n",
        "    \"value\", \"assess\", \"evaluate\", \"measure\", \"rate\", \"score\", \"grade\", \"review\",\n",
        "    \"endorse\", \"recommend\", \"reject\", \"approve\", \"disapprove\",\n",
        "\n",
        "    # Expressions of causation / change-of-state (leading to adj)\n",
        "    \"render\", \"make\", \"leave\", \"drive\"\n",
        "}\n",
        "\n",
        "\n",
        "# ---------- IO: parse conllu ----------\n",
        "def parse_conllu_file(path):\n",
        "    \"\"\"Return list of sentences; each sentence is a list of token dicts.\"\"\"\n",
        "    sentences = []\n",
        "    sent = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as fh:\n",
        "        for line in fh:\n",
        "            line = line.rstrip(\"\\n\")\n",
        "            if not line:\n",
        "                if sent:\n",
        "                    sentences.append(sent)\n",
        "                    sent = []\n",
        "                continue\n",
        "            if line.startswith(\"#\"):\n",
        "                continue\n",
        "            parts = line.split(\"\\t\")\n",
        "            if len(parts) < 8:\n",
        "                continue\n",
        "            if \"-\" in parts[0] or \".\" in parts[0]:\n",
        "                continue\n",
        "            try:\n",
        "                idx = int(parts[0])\n",
        "            except:\n",
        "                continue\n",
        "            token = {\n",
        "                \"id\": idx,\n",
        "                \"form\": parts[1],\n",
        "                \"lemma\": parts[2].lower(),\n",
        "                \"upos\": parts[3],\n",
        "                \"head\": int(parts[6]) if parts[6].isdigit() else 0,\n",
        "                \"deprel\": parts[7],\n",
        "            }\n",
        "            sent.append(token)\n",
        "    if sent:\n",
        "        sentences.append(sent)\n",
        "    return sentences\n",
        "\n",
        "# ---------- classification & example collection ----------\n",
        "def _append_example(adj_examples, lemma, category, sentence_text):\n",
        "    \"\"\"Append sentence_text to adj_examples[lemma][category] up to EXAMPLES_PER_CLASS, avoiding duplicates.\"\"\"\n",
        "    lst = adj_examples.setdefault(lemma, {\"affect\":[], \"judgement\":[], \"appreciation\":[], \"ambiguous\":[]})\n",
        "    if sentence_text in lst[category]:\n",
        "        return\n",
        "    if len(lst[category]) < EXAMPLES_PER_CLASS:\n",
        "        lst[category].append(sentence_text)\n",
        "\n",
        "def classify_adjectives_in_sentence(sent, adj_stats, adj_examples):\n",
        "    by_id = {t[\"id\"]: t for t in sent}\n",
        "    children = defaultdict(list)\n",
        "    for t in sent:\n",
        "        children[t[\"head\"]].append(t)\n",
        "\n",
        "    sentence_text = \" \".join(t[\"form\"] for t in sent)\n",
        "\n",
        "    for t in sent:\n",
        "        if t[\"upos\"] != \"ADJ\":\n",
        "            continue\n",
        "        lemma = t[\"lemma\"]\n",
        "        adj_stats[lemma][\"total\"] += 1\n",
        "\n",
        "        # find nsubj children of this ADJ (predicative adjective case)\n",
        "        subj_candidates = [c for c in children.get(t[\"id\"], []) if c[\"deprel\"].startswith(\"nsubj\")]\n",
        "        cop_children = [c for c in children.get(t[\"id\"], []) if c[\"deprel\"] == \"cop\"]\n",
        "        classified = False\n",
        "\n",
        "        # Case A: ADJ has explicit subject (nsubj)\n",
        "        if subj_candidates:\n",
        "            subj = subj_candidates[0]\n",
        "            s_lemma = subj[\"lemma\"]\n",
        "            s_upos = subj[\"upos\"]\n",
        "            if s_upos == \"PRON\" and s_lemma in FIRST_PERSON:\n",
        "                adj_stats[lemma][\"affect\"] += 1\n",
        "                _append_example(adj_examples, lemma, \"affect\", sentence_text)\n",
        "                classified = True\n",
        "            elif s_upos == \"PRON\" and s_lemma in THIRD_PERSON_PRONOUNS:\n",
        "                adj_stats[lemma][\"judgement\"] += 1\n",
        "                _append_example(adj_examples, lemma, \"judgement\", sentence_text)\n",
        "                classified = True\n",
        "            elif s_upos == \"PROPN\":\n",
        "                adj_stats[lemma][\"judgement\"] += 1\n",
        "                _append_example(adj_examples, lemma, \"judgement\", sentence_text)\n",
        "                classified = True\n",
        "            elif s_upos == \"PRON\" and s_lemma in APPRECIATION_PRONOUNS:\n",
        "                adj_stats[lemma][\"appreciation\"] += 1\n",
        "                _append_example(adj_examples, lemma, \"appreciation\", sentence_text)\n",
        "                classified = True\n",
        "            elif s_upos == \"NOUN\":\n",
        "                adj_stats[lemma][\"appreciation\"] += 1\n",
        "                _append_example(adj_examples, lemma, \"appreciation\", sentence_text)\n",
        "                classified = True\n",
        "\n",
        "        # Case B: ADJ is xcomp of a verb (I feel happy / she seems interesting)\n",
        "        if not classified and t[\"deprel\"] == \"xcomp\":\n",
        "            head = by_id.get(t[\"head\"])\n",
        "            if head and head[\"upos\"].startswith(\"V\"):\n",
        "                verb_children = children.get(head[\"id\"], [])\n",
        "                v_subjs = [c for c in verb_children if c[\"deprel\"].startswith(\"nsubj\")]\n",
        "                if v_subjs:\n",
        "                    vsub = v_subjs[0]\n",
        "                    vl = vsub[\"lemma\"]; vup = vsub[\"upos\"]\n",
        "                    if vup == \"PRON\" and vl in FIRST_PERSON:\n",
        "                        adj_stats[lemma][\"affect\"] += 1\n",
        "                        _append_example(adj_examples, lemma, \"affect\", sentence_text)\n",
        "                        classified = True\n",
        "                    elif vup == \"PRON\" and vl in THIRD_PERSON_PRONOUNS:\n",
        "                        adj_stats[lemma][\"judgement\"] += 1\n",
        "                        _append_example(adj_examples, lemma, \"judgement\", sentence_text)\n",
        "                        classified = True\n",
        "                    elif vup == \"PROPN\":\n",
        "                        adj_stats[lemma][\"judgement\"] += 1\n",
        "                        _append_example(adj_examples, lemma, \"judgement\", sentence_text)\n",
        "                        classified = True\n",
        "                    elif vup == \"NOUN\":\n",
        "                        adj_stats[lemma][\"appreciation\"] += 1\n",
        "                        _append_example(adj_examples, lemma, \"appreciation\", sentence_text)\n",
        "                        classified = True\n",
        "                else:\n",
        "                    # no explicit subject; guess by verb lemma\n",
        "                    if head[\"lemma\"] in FEEL_VERBS:\n",
        "                        adj_stats[lemma][\"affect\"] += 1\n",
        "                        _append_example(adj_examples, lemma, \"affect\", sentence_text)\n",
        "                        classified = True\n",
        "\n",
        "        # Case C: ADJ with copula child (e.g. \"I was happy\")\n",
        "        if not classified and cop_children:\n",
        "            if subj_candidates:\n",
        "                subj = subj_candidates[0]\n",
        "                sl = subj[\"lemma\"]; sup = subj[\"upos\"]\n",
        "                if sup == \"PRON\" and sl in FIRST_PERSON:\n",
        "                    adj_stats[lemma][\"affect\"] += 1\n",
        "                    _append_example(adj_examples, lemma, \"affect\", sentence_text)\n",
        "                    classified = True\n",
        "                elif sup == \"PRON\" and sl in THIRD_PERSON_PRONOUNS:\n",
        "                    adj_stats[lemma][\"judgement\"] += 1\n",
        "                    _append_example(adj_examples, lemma, \"judgement\", sentence_text)\n",
        "                    classified = True\n",
        "                elif sup == \"PROPN\":\n",
        "                    adj_stats[lemma][\"judgement\"] += 1\n",
        "                    _append_example(adj_examples, lemma, \"judgement\", sentence_text)\n",
        "                    classified = True\n",
        "                elif sup == \"NOUN\":\n",
        "                    adj_stats[lemma][\"appreciation\"] += 1\n",
        "                    _append_example(adj_examples, lemma, \"appreciation\", sentence_text)\n",
        "                    classified = True\n",
        "                elif sup == \"PRON\" and sl in APPRECIATION_PRONOUNS:\n",
        "                    adj_stats[lemma][\"appreciation\"] += 1\n",
        "                    _append_example(adj_examples, lemma, \"appreciation\", sentence_text)\n",
        "                    classified = True\n",
        "\n",
        "        # fallback: mark ambiguous if no classification matched\n",
        "        if not classified:\n",
        "            adj_stats[lemma][\"ambiguous\"] += 1\n",
        "            _append_example(adj_examples, lemma, \"ambiguous\", sentence_text)\n",
        "\n",
        "# ---------- aggregation ----------\n",
        "def compute_appraisal_with_examples_by_class(root, top_n=None, lang_filter=None):\n",
        "    all_rows = []\n",
        "    for lang in sorted(os.listdir(root)):\n",
        "        if lang_filter and lang != lang_filter:\n",
        "            continue\n",
        "        lpath = os.path.join(root, lang)\n",
        "        if not os.path.isdir(lpath):\n",
        "            continue\n",
        "        for disc in sorted(os.listdir(lpath)):\n",
        "            dpath = os.path.join(lpath, disc)\n",
        "            if not os.path.isdir(dpath):\n",
        "                continue\n",
        "\n",
        "            adj_stats = defaultdict(lambda: Counter({\"total\":0, \"affect\":0, \"judgement\":0, \"appreciation\":0, \"ambiguous\":0}))\n",
        "            adj_examples = {}  # lemma -> dict of lists for each class\n",
        "\n",
        "            # parse all files\n",
        "            for fname in sorted(os.listdir(dpath)):\n",
        "                if not fname.endswith(\".conllu\"):\n",
        "                    continue\n",
        "                path = os.path.join(dpath, fname)\n",
        "                sents = parse_conllu_file(path)\n",
        "                for s in sents:\n",
        "                    classify_adjectives_in_sentence(s, adj_stats, adj_examples)\n",
        "\n",
        "            # assemble rows\n",
        "            rows = []\n",
        "            for lemma, cnts in adj_stats.items():\n",
        "                tot = cnts[\"total\"]\n",
        "                aff = cnts[\"affect\"]\n",
        "                jud = cnts[\"judgement\"]\n",
        "                app = cnts[\"appreciation\"]\n",
        "                amb = cnts[\"ambiguous\"]\n",
        "                co_total = aff + jud + app\n",
        "                if co_total > 0:\n",
        "                    p_aff = aff / co_total\n",
        "                    p_jud = jud / co_total\n",
        "                    p_app = app / co_total\n",
        "                else:\n",
        "                    p_aff = p_jud = p_app = 0.0\n",
        "\n",
        "                examples = adj_examples.get(lemma, {\"affect\":[], \"judgement\":[], \"appreciation\":[], \"ambiguous\":[]})\n",
        "                # join example sentences with a visible separator\n",
        "                ex_aff = \" || \".join(examples[\"affect\"])\n",
        "                ex_jud = \" || \".join(examples[\"judgement\"])\n",
        "                ex_app = \" || \".join(examples[\"appreciation\"])\n",
        "                ex_amb = \" || \".join(examples[\"ambiguous\"])\n",
        "\n",
        "                rows.append({\n",
        "                    \"language\": lang,\n",
        "                    \"discipline\": disc,\n",
        "                    \"adjective\": lemma,\n",
        "                    \"total_count\": tot,\n",
        "                    \"affect_count\": aff,\n",
        "                    \"judgement_count\": jud,\n",
        "                    \"appreciation_count\": app,\n",
        "                    \"ambiguous_count\": amb,\n",
        "                    \"p_affect\": round(p_aff, 4),\n",
        "                    \"p_judgement\": round(p_jud, 4),\n",
        "                    \"p_appreciation\": round(p_app, 4),\n",
        "                    \"example_affect\": ex_aff,\n",
        "                    \"example_judgement\": ex_jud,\n",
        "                    \"example_appreciation\": ex_app,\n",
        "                    \"example_ambiguous\": ex_amb\n",
        "                })\n",
        "\n",
        "            # keep top_n by total_count for this (lang, discipline)\n",
        "            rows = sorted(rows, key=lambda r: r[\"total_count\"], reverse=True)\n",
        "            if top_n:\n",
        "                rows = rows[:top_n]\n",
        "            all_rows.extend(rows)\n",
        "    return all_rows\n",
        "\n",
        "# ---------- run ----------\n",
        "def main():\n",
        "    out = compute_appraisal_with_examples_by_class(CONLLU_ROOT, top_n=KEEP_TOP_N, lang_filter=\"en\")\n",
        "    if not out:\n",
        "        print(\"No results (check your CONLLU_ROOT path and folder structure).\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
        "    with open(OUT_CSV, \"w\", encoding=\"utf-8\", newline=\"\") as fh:\n",
        "        writer = csv.DictWriter(fh, fieldnames=list(out[0].keys()))\n",
        "        writer.writeheader()\n",
        "        for row in out:\n",
        "            writer.writerow(row)\n",
        "    print(\"Saved:\", OUT_CSV)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bDXp6WdSCOc",
        "outputId": "2fec9311-b5d3-416c-afb1-7e48b23fc351"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: conllu/adjectives_appraisal_with_examples_by_class.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trying out convertaffect\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ORa9ll8lUrVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "CONLLU_ROOT = \"conllu/conllu_file\"\n",
        "OUT_CSV = \"conllu/adjectives_appraisal_with_seedboost.csv\"\n",
        "SEED_PSEUDOCOUNT = 2    # how much to boost Affect count when adjective is in seed list\n",
        "KEEP_TOP_N = None       # not used; we pass top_n explicitly to compute_appraisal_with_seedboost\n",
        "\n",
        "# Patterns / heuristics\n",
        "FIRST_PERSON = {\n",
        "    # Subject + Object\n",
        "    \"i\", \"me\", \"we\", \"us\",\n",
        "    # Possessive determiners\n",
        "    \"my\", \"our\",\n",
        "    # Possessive pronouns\n",
        "    \"mine\", \"ours\",\n",
        "    # Reflexives\n",
        "    \"myself\", \"ourselves\"\n",
        "}\n",
        "\n",
        "# Second-person pronouns (for completeness — often neutral)\n",
        "SECOND_PERSON = {\n",
        "    \"you\",\n",
        "    # Possessive determiners\n",
        "    \"your\",\n",
        "    # Possessive pronouns\n",
        "    \"yours\",\n",
        "    # Reflexives\n",
        "    \"yourself\", \"yourselves\"\n",
        "}\n",
        "\n",
        "APPRECIATION_PRONOUNS = {\n",
        "    # Core expletive / dummy subject\n",
        "    \"it\", \"there\", \"here\",\n",
        "\n",
        "    # Demonstratives (singular/plural)\n",
        "    \"this\", \"that\", \"these\", \"those\",\n",
        "\n",
        "    # Indefinites referring to things/objects\n",
        "    \"something\", \"anything\", \"nothing\", \"everything\",\n",
        "    \"someone\", \"anyone\", \"no one\", \"everyone\",\n",
        "    \"somebody\", \"anybody\", \"nobody\", \"everybody\",\n",
        "\n",
        "    # Quantified / abstract pronouns\n",
        "    \"all\", \"each\", \"both\", \"neither\", \"none\", \"one\",\n",
        "\n",
        "    # Wh-pronouns often referring to things\n",
        "    \"what\", \"whatever\", \"which\", \"whichever\",\n",
        "\n",
        "    # Event-like references (treated as abstract appreciation subjects)\n",
        "    \"this one\", \"that one\", \"such\", \"so\"\n",
        "}\n",
        "\n",
        "FEEL_VERBS = {\n",
        "    # Core copular / linking\n",
        "    \"be\", \"become\", \"get\", \"remain\", \"stay\", \"keep\", \"prove\", \"turn\",\n",
        "\n",
        "    # Seem / appear / perception-of-truth\n",
        "    \"seem\", \"appear\", \"sound\", \"look\", \"smell\", \"taste\", \"feel\",\n",
        "\n",
        "    # Evaluation / cognition (mental stance)\n",
        "    \"think\", \"consider\", \"believe\", \"find\", \"judge\", \"deem\", \"regard\", \"suppose\",\n",
        "    \"reckon\", \"assume\", \"imagine\", \"guess\", \"suspect\", \"presume\", \"conclude\",\n",
        "\n",
        "    # Communication verbs that take complements\n",
        "    \"say\", \"claim\", \"argue\", \"maintain\", \"suggest\", \"assert\", \"contend\", \"report\",\n",
        "\n",
        "    # Desire / volition\n",
        "    \"want\", \"wish\", \"hope\", \"long\", \"yearn\", \"desire\", \"prefer\", \"intend\", \"plan\",\n",
        "    \"aim\", \"aspire\",\n",
        "\n",
        "    # Liking / disliking / attitude\n",
        "    \"like\", \"love\", \"enjoy\", \"admire\", \"appreciate\", \"cherish\", \"favor\", \"fancy\",\n",
        "    \"care\", \"mind\",\n",
        "    \"dislike\", \"hate\", \"detest\", \"despise\", \"loathe\", \"resent\", \"scorn\", \"disdain\",\n",
        "\n",
        "    # Emotional / affective\n",
        "    \"fear\", \"dread\", \"regret\", \"worry\", \"doubt\", \"mourn\", \"lament\", \"envy\", \"pity\",\n",
        "    \"sympathize\", \"empathize\", \"applaud\", \"praise\", \"criticize\", \"blame\", \"condemn\",\n",
        "\n",
        "    # Modal / necessity / obligation\n",
        "    \"must\", \"should\", \"ought\", \"need\", \"have_to\", \"require\", \"demand\", \"deserve\",\n",
        "\n",
        "    # Experiential / perception\n",
        "    \"watch\", \"observe\", \"notice\", \"perceive\", \"recognize\", \"detect\", \"spot\",\n",
        "\n",
        "    # Misc. evaluative\n",
        "    \"value\", \"assess\", \"evaluate\", \"measure\", \"rate\", \"score\", \"grade\", \"review\",\n",
        "    \"endorse\", \"recommend\", \"reject\", \"approve\", \"disapprove\",\n",
        "\n",
        "    # Expressions of causation / change-of-state (leading to adj)\n",
        "    \"render\", \"make\", \"leave\", \"drive\"\n",
        "}\n",
        "\n",
        "# NOTE: The code below references THIRD_PERSON_PRONOUNS in classification.\n",
        "# If you don't already have that set defined elsewhere, define a simple set here:\n",
        "THIRD_PERSON_PRONOUNS = {\"he\", \"she\", \"it\", \"they\", \"him\", \"her\", \"them\", \"his\", \"hers\", \"theirs\"}\n",
        "\n",
        "# for loading conllu file\n",
        "def parse_conllu_file(path):\n",
        "    \"\"\"Parse CONLLU file into list of sentences; each sentence is a list of token dicts.\n",
        "       Assumes standard UD CONLLU columns (index, form, lemma, upos, ... head, deprel at cols 7/8).\"\"\"\n",
        "    sentences = []\n",
        "    sent = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as fh:\n",
        "        for line in fh:\n",
        "            line = line.rstrip(\"\\n\")\n",
        "            if not line:\n",
        "                if sent:\n",
        "                    sentences.append(sent)\n",
        "                    sent = []\n",
        "                continue\n",
        "            if line.startswith(\"#\"):\n",
        "                continue\n",
        "            parts = line.split(\"\\t\")\n",
        "            if len(parts) < 8:\n",
        "                continue\n",
        "            # skip multiword or empty token lines\n",
        "            if \"-\" in parts[0] or \".\" in parts[0]:\n",
        "                continue\n",
        "            try:\n",
        "                idx = int(parts[0])\n",
        "            except:\n",
        "                continue\n",
        "            token = {\n",
        "                \"id\": idx,\n",
        "                \"form\": parts[1],\n",
        "                \"lemma\": parts[2].lower(),\n",
        "                \"upos\": parts[3],\n",
        "                \"head\": int(parts[6]) if parts[6].isdigit() else 0,\n",
        "                \"deprel\": parts[7],\n",
        "            }\n",
        "            sent.append(token)\n",
        "    if sent:\n",
        "        sentences.append(sent)\n",
        "    return sentences\n",
        "\n",
        "# ---------- classification logic ----------\n",
        "def classify_adjectives_in_sentence(sent, adj_stats):\n",
        "    by_id = {t[\"id\"]: t for t in sent}\n",
        "    children = defaultdict(list)\n",
        "    for t in sent:\n",
        "        children[t[\"head\"]].append(t)\n",
        "\n",
        "    for t in sent:\n",
        "        if t[\"upos\"] != \"ADJ\":\n",
        "            continue\n",
        "        lemma = t[\"lemma\"]\n",
        "        adj_stats[lemma][\"total\"] += 1\n",
        "\n",
        "        # find nsubj children of this ADJ (predicative adjective case)\n",
        "        subj_candidates = [c for c in children.get(t[\"id\"], []) if c[\"deprel\"].startswith(\"nsubj\")]\n",
        "        cop_children = [c for c in children.get(t[\"id\"], []) if c[\"deprel\"] == \"cop\"]\n",
        "        classified = False\n",
        "\n",
        "        # Case A: ADJ has explicit subject (nsubj)\n",
        "        if subj_candidates:\n",
        "            subj = subj_candidates[0]\n",
        "            s_lemma = subj[\"lemma\"]\n",
        "            s_upos = subj[\"upos\"]\n",
        "            if s_upos == \"PRON\" and s_lemma in FIRST_PERSON:\n",
        "                adj_stats[lemma][\"affect\"] += 1\n",
        "                classified = True\n",
        "            elif s_upos == \"PRON\" and s_lemma in THIRD_PERSON_PRONOUNS:\n",
        "                adj_stats[lemma][\"judgement\"] += 1\n",
        "                classified = True\n",
        "            elif s_upos == \"PROPN\":\n",
        "                adj_stats[lemma][\"judgement\"] += 1\n",
        "                classified = True\n",
        "            elif s_upos == \"PRON\" and s_lemma in APPRECIATION_PRONOUNS:\n",
        "                adj_stats[lemma][\"appreciation\"] += 1\n",
        "                classified = True\n",
        "            elif s_upos == \"NOUN\":\n",
        "                adj_stats[lemma][\"appreciation\"] += 1\n",
        "                classified = True\n",
        "\n",
        "        # Case B: ADJ is xcomp of a verb (I feel happy / she seems interesting)\n",
        "        if not classified and t[\"deprel\"] == \"xcomp\":\n",
        "            head = by_id.get(t[\"head\"])\n",
        "            if head and head[\"upos\"].startswith(\"V\"):\n",
        "                verb_children = children.get(head[\"id\"], [])\n",
        "                v_subjs = [c for c in verb_children if c[\"deprel\"].startswith(\"nsubj\")]\n",
        "                if v_subjs:\n",
        "                    vsub = v_subjs[0]\n",
        "                    vl = vsub[\"lemma\"]; vup = vsub[\"upos\"]\n",
        "                    if vup == \"PRON\" and vl in FIRST_PERSON:\n",
        "                        adj_stats[lemma][\"affect\"] += 1\n",
        "                        classified = True\n",
        "                    elif vup == \"PRON\" and vl in THIRD_PERSON_PRONOUNS:\n",
        "                        adj_stats[lemma][\"judgement\"] += 1\n",
        "                        classified = True\n",
        "                    elif vup == \"PROPN\":\n",
        "                        adj_stats[lemma][\"judgement\"] += 1\n",
        "                        classified = True\n",
        "                    elif vup == \"NOUN\":\n",
        "                        adj_stats[lemma][\"appreciation\"] += 1\n",
        "                        classified = True\n",
        "                else:\n",
        "                    # no explicit subject; guess by verb lemma\n",
        "                    if head[\"lemma\"] in FEEL_VERBS:\n",
        "                        adj_stats[lemma][\"affect\"] += 1\n",
        "                        classified = True\n",
        "\n",
        "        # Case C: ADJ with copula child (e.g. \"I was happy\")\n",
        "        if not classified and cop_children:\n",
        "            if subj_candidates:\n",
        "                subj = subj_candidates[0]\n",
        "                sl = subj[\"lemma\"]; sup = subj[\"upos\"]\n",
        "                if sup == \"PRON\" and sl in FIRST_PERSON:\n",
        "                    adj_stats[lemma][\"affect\"] += 1\n",
        "                    classified = True\n",
        "                elif sup == \"PRON\" and sl in THIRD_PERSON_PRONOUNS:\n",
        "                    adj_stats[lemma][\"judgement\"] += 1\n",
        "                    classified = True\n",
        "                elif sup == \"PROPN\":\n",
        "                    adj_stats[lemma][\"judgement\"] += 1\n",
        "                    classified = True\n",
        "                elif sup == \"NOUN\":\n",
        "                    adj_stats[lemma][\"appreciation\"] += 1\n",
        "                    classified = True\n",
        "                elif sup == \"PRON\" and sl in APPRECIATION_PRONOUNS:\n",
        "                    adj_stats[lemma][\"appreciation\"] += 1\n",
        "                    classified = True\n",
        "\n",
        "        # fallback: mark ambiguous if no classification matched\n",
        "        if not classified:\n",
        "            adj_stats[lemma][\"ambiguous\"] += 1\n",
        "\n",
        "# ---------- seed logic ----------\n",
        "def compute_appraisal_with_seedboost(root, seed_set, seed_pseudocount=2, top_n=None, lang_filter=None):\n",
        "    \"\"\"\n",
        "    root: path containing language subfolders (e.g., conllu/conllu_file)\n",
        "    lang_filter: if set (e.g. \"en\") only that language folder will be processed.\n",
        "    top_n: keep top-N adjectives per (lang,discipline) by total_count if provided.\n",
        "    \"\"\"\n",
        "    all_rows = []\n",
        "    for lang in sorted(os.listdir(root)):\n",
        "        if lang_filter and lang != lang_filter:\n",
        "            continue\n",
        "        lpath = os.path.join(root, lang)\n",
        "        if not os.path.isdir(lpath):\n",
        "            continue\n",
        "        for disc in sorted(os.listdir(lpath)):\n",
        "            dpath = os.path.join(lpath, disc)\n",
        "            if not os.path.isdir(dpath):\n",
        "                continue\n",
        "\n",
        "            adj_stats = defaultdict(lambda: Counter({\"total\":0, \"affect\":0, \"judgement\":0, \"appreciation\":0, \"ambiguous\":0}))\n",
        "\n",
        "            # parse all files\n",
        "            for fname in os.listdir(dpath):\n",
        "                if not fname.endswith(\".conllu\"):\n",
        "                    continue\n",
        "                path = os.path.join(dpath, fname)\n",
        "                sents = parse_conllu_file(path)\n",
        "                for s in sents:\n",
        "                    classify_adjectives_in_sentence(s, adj_stats)\n",
        "\n",
        "            # assemble rows\n",
        "            rows = []\n",
        "            for lemma, cnts in adj_stats.items():\n",
        "                tot = cnts[\"total\"]\n",
        "                aff = cnts[\"affect\"]\n",
        "                jud = cnts[\"judgement\"]\n",
        "                app = cnts[\"appreciation\"]\n",
        "                amb = cnts[\"ambiguous\"]\n",
        "                co_total = aff + jud + app\n",
        "                # raw normalized (corpus evidence only)\n",
        "                if co_total > 0:\n",
        "                    p_aff = aff / co_total\n",
        "                    p_jud = jud / co_total\n",
        "                    p_app = app / co_total\n",
        "                else:\n",
        "                    p_aff = p_jud = p_app = 0.0\n",
        "\n",
        "                # seed boost: add pseudo-count to Affect if lemma in seed set\n",
        "                aff_boost = aff + (seed_pseudocount if lemma in seed_set else 0)\n",
        "                co_total_boost = aff_boost + jud + app\n",
        "                if co_total_boost > 0:\n",
        "                    p_aff_boost = aff_boost / co_total_boost\n",
        "                    p_jud_boost = jud / co_total_boost\n",
        "                    p_app_boost = app / co_total_boost\n",
        "                else:\n",
        "                    p_aff_boost = p_jud_boost = p_app_boost = 0.0\n",
        "\n",
        "                rows.append({\n",
        "                    \"language\": lang,\n",
        "                    \"discipline\": disc,\n",
        "                    \"adjective\": lemma,\n",
        "                    \"total_count\": tot,\n",
        "                    \"affect_count\": aff,\n",
        "                    \"judgement_count\": jud,\n",
        "                    \"appreciation_count\": app,\n",
        "                    \"ambiguous_count\": amb,\n",
        "                    \"p_affect\": round(p_aff, 4),\n",
        "                    \"p_judgement\": round(p_jud, 4),\n",
        "                    \"p_appreciation\": round(p_app, 4),\n",
        "                    \"seed_affect\": (lemma in seed_set),\n",
        "                    \"p_affect_seed\": round(p_aff_boost, 4),\n",
        "                    \"p_judgement_seed\": round(p_jud_boost, 4),\n",
        "                    \"p_appreciation_seed\": round(p_app_boost, 4),\n",
        "                })\n",
        "\n",
        "            # optionally keep top_n by total_count\n",
        "            rows = sorted(rows, key=lambda r: r[\"total_count\"], reverse=True)\n",
        "            if top_n:\n",
        "                rows = rows[:top_n]\n",
        "            all_rows.extend(rows)\n",
        "    return all_rows\n",
        "\n",
        "# ---------- run ----------\n",
        "def main():\n",
        "    seed_set = [\"angst-ridden\",\"amused\",\"buoyant\",\"carried away\",\"cheerful\",\"cheery\",\"chipper\",\"chirpy\",\"content\",\"contented\",\"delighted\",\"delirious\",\"ecstatic\",\"elated\",\"enraptured\",\"enthused\",\"euphoric\",\"exhilarated\",\"exultant\",\"feverish\",\"glad\",\"gladdened\",\"gleeful\",\"gratified\",\"happy\",\"honoured\",\"joyful\",\"joyous\",\"jubilant\",\"keyed-up\",\"light-hearted\",\"manic\",\"merry\",\"mirthful\",\"over-excited\",\"overjoyed\",\"pleased\",\"proud\",\"satisfied\",\"starry-eyed\",\"thankful\",\"thrilled\",\"tickled\",\"touched\",\"triumphant\",\"upbeat\",\"uplifted\",\"admiring\",\"adoring\",\"amorous\",\"appreciative\",\"approving\",\"bedazzled\",\"besotted\",\"bewitched\",\"broody\",\"charmed\",\"chuffed\",\"crazy\",\"doting\",\"dotty\",\"enamoured\",\"enchanted\",\"enthusiastic\",\"fanatical\",\"fervent\",\"fervid\",\"fulfilled\",\"grateful\",\"hung up\",\"indebted\",\"infatuated\",\"keen\",\"lovesick\",\"love-struck\",\"mad\",\"obligated\",\"partial\",\"rabid\",\"smitten\",\"sold\",\"taken with\",\"well-disposed\",\"worshipful\",\"agog\",\"anxious\",\"bursting\",\"desirous\",\"desperate\",\"edgy\",\"fevered\",\"heedful\",\"hungry\",\"itching\",\"passionate\",\"prepared\",\"psyched up\",\"stirred up\",\"uptight\",\"wholehearted\",\"willing\",\"affronted\",\"aggrieved\",\"agonised\",\"anguished\",\"blue\",\"broken-hearted\",\"browned-off\",\"bruised\",\"burdened\",\"chagrined\",\"cheesed off\",\"conscience-stricken\",\"crestfallen\",\"cut up\",\"deflated\",\"dejected\",\"demoralized\",\"depressed\",\"desolate\",\"despairing\",\"despondent\",\"devastated\",\"disappointed\",\"disconsolate\",\"discontented\",\"discouraged\",\"disenchanted\",\"disgusted\",\"disheartened\",\"disillusioned\",\"dismayed\",\"dispirited\",\"distressed\",\"doleful\",\"down\",\"downcast\",\"downhearted\",\"fed up\",\"forlorn\",\"gloomy\",\"glum\",\"gutted\",\"harrassed\",\"heartbroken\",\"heavy-hearted\",\"heavy-laden\",\"homesick\",\"hopeless\",\"horrified\",\"huffy\",\"hurt\",\"hurting\",\"inconsolable\",\"low\",\"malcontent\",\"melancholic\",\"miffed\",\"miserable\",\"morose\",\"mournful\",\"offended\",\"overwhelmed\",\"pressured\",\"rotten\",\"sad\",\"saddened\",\"self-pitying\",\"shattered\",\"sick\",\"sickened\",\"sombre\",\"sorrowful\",\"sorrowing\",\"stung\",\"suicidal\",\"tired\",\"tormented\",\"traumatized\",\"unhappy\",\"unhopeful\",\"unsatisfied\",\"woeful\",\"wounded\",\"wretched\",\"addled\",\"addlepated\",\"agitated\",\"alarmed\",\"apprehensive\",\"baffled\",\"bewildered\",\"bothered\",\"concerned\",\"disconcerted\",\"distraught\",\"disturbed\",\"excited\",\"fearful\",\"flummoxed\",\"flustered\",\"frantic\",\"fraught\",\"het up\",\"jittery\",\"jumpy\",\"moonstruck\",\"mystified\",\"nervous\",\"nervy\",\"nonplussed\",\"overstrung\",\"overwrought\",\"perplexed\",\"perturbed\",\"punch-drunk\",\"puzzled\",\"shaken\",\"stressed\",\"stumped\",\"stupefied\",\"tense\",\"troubled\",\"twitchy\",\"uneasy\",\"unsettled\",\"wired\",\"worked-up\",\"worried\",\"wrought-up\",\"aggravated\",\"angry\",\"annoyed\",\"antagonistic\",\"antipathetic\",\"antsy\",\"apoplectic\",\"bad-tempered\",\"bitter\",\"choleric\",\"crabbed\",\"crabby\",\"cranky\",\"crazed\",\"cross\",\"crotchety\",\"disgruntled\",\"displeased\",\"dissatisfied\",\"embittered\",\"enraged\",\"exasperated\",\"fractious\",\"frenzied\",\"frustrated\",\"fuming\",\"furious\",\"grouchy\",\"grumpy\",\"hacked off\",\"ill-disposed\",\"impatient\",\"incensed\",\"indignant\",\"infuriated\",\"irate\",\"ireful\",\"irked\",\"irritable\",\"irritated\",\"livid\",\"maddened\",\"narked\",\"nettled\",\"outraged\",\"peeved\",\"peevish\",\"petulant\",\"piqued\",\"rancorous\",\"ratty\",\"riled\",\"seething\",\"sore\",\"strung up\",\"sulky\",\"teed off\",\"testy\",\"tetchy\",\"ticked off\",\"vengeful\",\"vexed\",\"vindictive\",\"waspish\",\"wrathful\",\"abashed\",\"apologetic\",\"ashamed\",\"contrite\",\"deprecatory\",\"embarrassed\",\"guilt-ridden\",\"guilty\",\"humbled\",\"humiliated\",\"mortified\",\"penitent\",\"regretful\",\"remorseful\",\"repentant\",\"rueful\",\"shamefaced\",\"sheepish\",\"afraid\",\"cowed\",\"frightened\",\"horror-stricken\",\"intimidated\",\"panicked\",\"panicky\",\"panic-stricken\",\"petrified\",\"scared\",\"terrified\",\"terrorised\",\"terror-stricken\",\"unnerved\",\"daunted\",\"discomfited\",\"disquieted\",\"mistrustful\",\"paranoid\",\"queasy\",\"squirmy\",\"unglued\",\"aghast\",\"amazed\",\"appalled\",\"astonished\",\"astounded\",\"awe-stricken\",\"awe-struck\",\"bowled over\",\"electrified\",\"flabbergasted\",\"gob-smacked\",\"horror-struck\",\"impressed\",\"incredulous\",\"knocked out\",\"overawed\",\"scandalised\",\"shocked\",\"staggered\",\"startled\",\"stunned\",\"stupefied\",\"surprised\",\"taken aback\",\"thunderstruck\",\"covetous\",\"envious\",\"green-eyed\",\"jealous\",\"territorial\",\"avid\",\"bent on\",\"dying\",\"eager\",\"gasping for\",\"intent\"\n",
        "    ]\n",
        "    print(f\"Loaded {len(seed_set)} seed items from Bednarek (sample): {list(seed_set)[:10]}\")\n",
        "\n",
        "    # Run only for English (\"en\") and keep top 20 adjectives per (lang, discipline)\n",
        "    out = compute_appraisal_with_seedboost(CONLLU_ROOT, seed_set, seed_pseudocount=SEED_PSEUDOCOUNT, top_n=20, lang_filter=\"en\")\n",
        "    if not out:\n",
        "        print(\"No results (check your CONLLU_ROOT path and folder structure).\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
        "    with open(OUT_CSV, \"w\", encoding=\"utf-8\", newline=\"\") as fh:\n",
        "        writer = csv.DictWriter(fh, fieldnames=list(out[0].keys()))\n",
        "        writer.writeheader()\n",
        "        for row in out:\n",
        "            writer.writerow(row)\n",
        "    print(\"Saved:\", OUT_CSV)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NDczS_1EukR",
        "outputId": "a117453a-a260-4f6b-d272-f97b3d207f78"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 371 seed items from Bednarek (sample): ['angst-ridden', 'amused', 'buoyant', 'carried away', 'cheerful', 'cheery', 'chipper', 'chirpy', 'content', 'contented']\n",
            "Saved: conllu/adjectives_appraisal_with_seedboost.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HbSALBC_TbHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}