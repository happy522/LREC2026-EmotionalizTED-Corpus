{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c648c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.16.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\khushi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install simalign==1.0.8    # or latest simalign\n",
    "!pip install pandas scipy tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f06ad00",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/conllu_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 321\u001b[39m\n\u001b[32m    314\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsed confidence threshold = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 302\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(threshold)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m(threshold=CONFIDENCE_THRESHOLD):\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     out = \u001b[43mcompute_appraisal_with_examples_by_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONLLU_ROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKEEP_TOP_N\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out:\n\u001b[32m    304\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo results (check your CONLLU_ROOT path and folder structure).\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 197\u001b[39m, in \u001b[36mcompute_appraisal_with_examples_by_class\u001b[39m\u001b[34m(root, top_n, lang_filter, confidence_threshold)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_appraisal_with_examples_by_class\u001b[39m(root, top_n=\u001b[38;5;28;01mNone\u001b[39;00m, lang_filter=\u001b[38;5;28;01mNone\u001b[39;00m, confidence_threshold=\u001b[32m0.50\u001b[39m):\n\u001b[32m    196\u001b[39m     all_rows = []\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m lang_filter \u001b[38;5;129;01mand\u001b[39;00m lang != lang_filter:\n\u001b[32m    199\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '/conllu_file'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "CONLLU_ROOT = \"/conllu_file\"\n",
    "OUT_CSV = \"adjectives_appraisal_with_examples_by_Domain_thresholded.csv\"\n",
    "KEEP_TOP_N = 20            # top-N adjectives per (lang, Domain) by total count\n",
    "EXAMPLES_PER_CLASS = 5     # how many example sentences to keep per classification\n",
    "CONFIDENCE_THRESHOLD = 0.50  # set to 0.50 or 0.60 as desired\n",
    "# ---------- end CONFIG ----------\n",
    "\n",
    "# ---- (keep your pattern sets unchanged) ----\n",
    "FIRST_PERSON = {\n",
    "    \"i\", \"me\", \"we\", \"us\",\n",
    "    \"my\", \"our\",\n",
    "    \"mine\", \"ours\",\n",
    "    \"myself\", \"ourselves\"\n",
    "}\n",
    "SECOND_PERSON = {\"you\", \"your\", \"yours\", \"yourself\", \"yourselves\"}\n",
    "THIRD_PERSON_PRONOUNS = {\"he\", \"she\", \"it\", \"they\", \"him\", \"her\", \"them\", \"his\", \"hers\", \"theirs\"}\n",
    "APPRECIATION_PRONOUNS = {\n",
    "    \"it\", \"there\", \"here\", \"this\", \"that\", \"these\", \"those\",\n",
    "    \"something\", \"anything\", \"nothing\", \"everything\",\n",
    "    \"someone\", \"anyone\", \"no one\", \"everyone\",\n",
    "    \"somebody\", \"anybody\", \"nobody\", \"everybody\",\n",
    "    \"all\", \"each\", \"both\", \"neither\", \"none\", \"one\",\n",
    "    \"what\", \"whatever\", \"which\", \"whichever\",\n",
    "    \"this one\", \"that one\", \"such\", \"so\"\n",
    "}\n",
    "FEEL_VERBS = {\n",
    "    \"be\", \"become\", \"get\", \"remain\", \"stay\", \"keep\", \"prove\", \"turn\",\n",
    "    \"seem\", \"appear\", \"sound\", \"look\", \"smell\", \"taste\", \"feel\",\n",
    "    \"think\", \"consider\", \"believe\", \"find\", \"judge\", \"deem\", \"regard\",\n",
    "    \"say\", \"claim\", \"argue\", \"maintain\", \"suggest\", \"assert\", \"contend\",\n",
    "    \"want\", \"wish\", \"hope\", \"desire\", \"prefer\",\n",
    "    \"like\", \"love\", \"enjoy\", \"admire\", \"appreciate\",\n",
    "    \"dislike\", \"hate\", \"detest\", \"despise\",\n",
    "    \"fear\", \"dread\", \"regret\", \"worry\", \"doubt\", \"mourn\",\n",
    "    \"must\", \"should\", \"ought\", \"need\", \"have_to\",\n",
    "    \"watch\", \"observe\", \"notice\", \"perceive\", \"recognize\",\n",
    "    \"value\", \"assess\", \"evaluate\", \"review\", \"approve\", \"disapprove\",\n",
    "    \"render\", \"make\", \"leave\", \"drive\"\n",
    "}\n",
    "\n",
    "# ---------- IO: parse conllu ----------\n",
    "def parse_conllu_file(path):\n",
    "    \"\"\"Return list of sentences; each sentence is a list of token dicts.\"\"\"\n",
    "    sentences = []\n",
    "    sent = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as fh:\n",
    "        for line in fh:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line:\n",
    "                if sent:\n",
    "                    sentences.append(sent)\n",
    "                    sent = []\n",
    "                continue\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) < 8:\n",
    "                continue\n",
    "            if \"-\" in parts[0] or \".\" in parts[0]:\n",
    "                continue\n",
    "            try:\n",
    "                idx = int(parts[0])\n",
    "            except:\n",
    "                continue\n",
    "            token = {\n",
    "                \"id\": idx,\n",
    "                \"form\": parts[1],\n",
    "                \"lemma\": parts[2].lower(),\n",
    "                \"upos\": parts[3],\n",
    "                \"head\": int(parts[6]) if parts[6].isdigit() else 0,\n",
    "                \"deprel\": parts[7],\n",
    "            }\n",
    "            sent.append(token)\n",
    "    if sent:\n",
    "        sentences.append(sent)\n",
    "    return sentences\n",
    "\n",
    "# ---------- classification & example collection ----------\n",
    "def _append_example(adj_examples, lemma, category, sentence_text):\n",
    "    \"\"\"Append sentence_text to adj_examples[lemma][category] up to EXAMPLES_PER_CLASS, avoiding duplicates.\"\"\"\n",
    "    lst = adj_examples.setdefault(lemma, {\"Affect\":[], \"Judgement\":[], \"Appreciation\":[], \"ambiguous\":[]})\n",
    "    if sentence_text in lst[category]:\n",
    "        return\n",
    "    if len(lst[category]) < EXAMPLES_PER_CLASS:\n",
    "        lst[category].append(sentence_text)\n",
    "\n",
    "def classify_adjectives_in_sentence(sent, adj_stats, adj_examples):\n",
    "    by_id = {t[\"id\"]: t for t in sent}\n",
    "    children = defaultdict(list)\n",
    "    for t in sent:\n",
    "        children[t[\"head\"]].append(t)\n",
    "\n",
    "    sentence_text = \" \".join(t[\"form\"] for t in sent)\n",
    "\n",
    "    for t in sent:\n",
    "        if t[\"upos\"] != \"ADJ\":\n",
    "            continue\n",
    "        lemma = t[\"lemma\"]\n",
    "        adj_stats[lemma][\"total\"] += 1\n",
    "\n",
    "        subj_candidates = [c for c in children.get(t[\"id\"], []) if c[\"deprel\"].startswith(\"nsubj\")]\n",
    "        cop_children = [c for c in children.get(t[\"id\"], []) if c[\"deprel\"] == \"cop\"]\n",
    "        classified = False\n",
    "\n",
    "        if subj_candidates:\n",
    "            subj = subj_candidates[0]\n",
    "            s_lemma = subj[\"lemma\"]\n",
    "            s_upos = subj[\"upos\"]\n",
    "            if s_upos == \"PRON\" and s_lemma in FIRST_PERSON:\n",
    "                adj_stats[lemma][\"Affect\"] += 1\n",
    "                _append_example(adj_examples, lemma, \"Affect\", sentence_text)\n",
    "                classified = True\n",
    "            elif s_upos == \"PRON\" and s_lemma in THIRD_PERSON_PRONOUNS:\n",
    "                adj_stats[lemma][\"Judgement\"] += 1\n",
    "                _append_example(adj_examples, lemma, \"Judgement\", sentence_text)\n",
    "                classified = True\n",
    "            elif s_upos == \"PROPN\":\n",
    "                adj_stats[lemma][\"Judgement\"] += 1\n",
    "                _append_example(adj_examples, lemma, \"Judgement\", sentence_text)\n",
    "                classified = True\n",
    "            elif s_upos == \"PRON\" and s_lemma in APPRECIATION_PRONOUNS:\n",
    "                adj_stats[lemma][\"Appreciation\"] += 1\n",
    "                _append_example(adj_examples, lemma, \"Appreciation\", sentence_text)\n",
    "                classified = True\n",
    "            elif s_upos == \"NOUN\":\n",
    "                adj_stats[lemma][\"Appreciation\"] += 1\n",
    "                _append_example(adj_examples, lemma, \"Appreciation\", sentence_text)\n",
    "                classified = True\n",
    "\n",
    "        if not classified and t[\"deprel\"] == \"xcomp\":\n",
    "            head = by_id.get(t[\"head\"])\n",
    "            if head and head[\"upos\"].startswith(\"V\"):\n",
    "                verb_children = children.get(head[\"id\"], [])\n",
    "                v_subjs = [c for c in verb_children if c[\"deprel\"].startswith(\"nsubj\")]\n",
    "                if v_subjs:\n",
    "                    vsub = v_subjs[0]\n",
    "                    vl = vsub[\"lemma\"]; vup = vsub[\"upos\"]\n",
    "                    if vup == \"PRON\" and vl in FIRST_PERSON:\n",
    "                        adj_stats[lemma][\"Affect\"] += 1\n",
    "                        _append_example(adj_examples, lemma, \"Affect\", sentence_text)\n",
    "                        classified = True\n",
    "                    elif vup == \"PRON\" and vl in THIRD_PERSON_PRONOUNS:\n",
    "                        adj_stats[lemma][\"Judgement\"] += 1\n",
    "                        _append_example(adj_examples, lemma, \"Judgement\", sentence_text)\n",
    "                        classified = True\n",
    "                    elif vup == \"PROPN\":\n",
    "                        adj_stats[lemma][\"Judgement\"] += 1\n",
    "                        _append_example(adj_examples, lemma, \"Judgement\", sentence_text)\n",
    "                        classified = True\n",
    "                    elif vup == \"NOUN\":\n",
    "                        adj_stats[lemma][\"Appreciation\"] += 1\n",
    "                        _append_example(adj_examples, lemma, \"Appreciation\", sentence_text)\n",
    "                        classified = True\n",
    "                else:\n",
    "                    if head[\"lemma\"] in FEEL_VERBS:\n",
    "                        adj_stats[lemma][\"Affect\"] += 1\n",
    "                        _append_example(adj_examples, lemma, \"Affect\", sentence_text)\n",
    "                        classified = True\n",
    "\n",
    "        if not classified and cop_children:\n",
    "            if subj_candidates:\n",
    "                subj = subj_candidates[0]\n",
    "                sl = subj[\"lemma\"]; sup = subj[\"upos\"]\n",
    "                if sup == \"PRON\" and sl in FIRST_PERSON:\n",
    "                    adj_stats[lemma][\"Affect\"] += 1\n",
    "                    _append_example(adj_examples, lemma, \"Affect\", sentence_text)\n",
    "                    classified = True\n",
    "                elif sup == \"PRON\" and sl in THIRD_PERSON_PRONOUNS:\n",
    "                    adj_stats[lemma][\"Judgement\"] += 1\n",
    "                    _append_example(adj_examples, lemma, \"Judgement\", sentence_text)\n",
    "                    classified = True\n",
    "                elif sup == \"PROPN\":\n",
    "                    adj_stats[lemma][\"Judgement\"] += 1\n",
    "                    _append_example(adj_examples, lemma, \"Judgement\", sentence_text)\n",
    "                    classified = True\n",
    "                elif sup == \"NOUN\":\n",
    "                    adj_stats[lemma][\"Appreciation\"] += 1\n",
    "                    _append_example(adj_examples, lemma, \"Appreciation\", sentence_text)\n",
    "                    classified = True\n",
    "                elif sup == \"PRON\" and sl in APPRECIATION_PRONOUNS:\n",
    "                    adj_stats[lemma][\"Appreciation\"] += 1\n",
    "                    _append_example(adj_examples, lemma, \"Appreciation\", sentence_text)\n",
    "                    classified = True\n",
    "\n",
    "        if not classified:\n",
    "            adj_stats[lemma][\"ambiguous\"] += 1\n",
    "            _append_example(adj_examples, lemma, \"ambiguous\", sentence_text)\n",
    "\n",
    "# ---------- aggregation (with thresholding) ----------\n",
    "def compute_appraisal_with_examples_by_class(root, top_n=None, lang_filter=None, confidence_threshold=0.50):\n",
    "    all_rows = []\n",
    "    for lang in sorted(os.listdir(root)):\n",
    "        if lang_filter and lang != lang_filter:\n",
    "            continue\n",
    "        lpath = os.path.join(root, lang)\n",
    "        if not os.path.isdir(lpath):\n",
    "            continue\n",
    "        for Domain in sorted(os.listdir(lpath)):\n",
    "            dpath = os.path.join(lpath, Domain)\n",
    "            if not os.path.isdir(dpath):\n",
    "                continue\n",
    "\n",
    "            # Capitalize Domain names\n",
    "            Domain = Domain.capitalize()\n",
    "\n",
    "            adj_stats = defaultdict(lambda: Counter({\"total\":0, \"Affect\":0, \"Judgement\":0, \"Appreciation\":0, \"ambiguous\":0}))\n",
    "            adj_examples = {}\n",
    "\n",
    "            for fname in sorted(os.listdir(dpath)):\n",
    "                if not fname.endswith(\".conllu\"):\n",
    "                    continue\n",
    "                path = os.path.join(dpath, fname)\n",
    "                sents = parse_conllu_file(path)\n",
    "                for s in sents:\n",
    "                    classify_adjectives_in_sentence(s, adj_stats, adj_examples)\n",
    "\n",
    "            rows = []\n",
    "            for lemma, cnts in adj_stats.items():\n",
    "                tot = cnts[\"total\"]\n",
    "                aff = cnts[\"Affect\"]\n",
    "                jud = cnts[\"Judgement\"]\n",
    "                app = cnts[\"Appreciation\"]\n",
    "                amb = cnts[\"ambiguous\"]\n",
    "                co_total = aff + jud + app\n",
    "                if co_total > 0:\n",
    "                    p_aff = aff / co_total\n",
    "                    p_jud = jud / co_total\n",
    "                    p_app = app / co_total\n",
    "                else:\n",
    "                    p_aff = p_jud = p_app = 0.0\n",
    "\n",
    "                probs = {\"Affect\": p_aff, \"Judgement\": p_jud, \"Appreciation\": p_app}\n",
    "                max_prob = max(probs.values())\n",
    "                classes_meeting = [k for k, v in probs.items() if v >= confidence_threshold]\n",
    "                assigned_class = None\n",
    "                assigned_reason = \"\"\n",
    "                is_confident = False\n",
    "\n",
    "                if len(classes_meeting) == 1:\n",
    "                    assigned_class = classes_meeting[0]\n",
    "                    is_confident = True\n",
    "                    assigned_reason = f\"single_class_above_threshold ({confidence_threshold})\"\n",
    "                elif len(classes_meeting) > 1:\n",
    "                    sorted_by_prob = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "                    top_name, top_val = sorted_by_prob[0]\n",
    "                    second_val = sorted_by_prob[1][1]\n",
    "                    if top_val > second_val and top_val >= confidence_threshold:\n",
    "                        assigned_class = top_name\n",
    "                        is_confident = True\n",
    "                        assigned_reason = \"highest_prob_above_threshold (others below)\"\n",
    "                    else:\n",
    "                        assigned_class = \"ambiguous_tie\"\n",
    "                        assigned_reason = \"multiple_classes_above_threshold_or_tied\"\n",
    "                else:\n",
    "                    if max_prob == 0:\n",
    "                        assigned_class = \"ambiguous_no_evidence\"\n",
    "                        assigned_reason = \"no_Affect/Judgement/Appreciation_evidence\"\n",
    "                    else:\n",
    "                        assigned_class = \"ambiguous_low_confidence\"\n",
    "                        assigned_reason = f\"max_prob_below_threshold ({max_prob:.3f} < {confidence_threshold})\"\n",
    "                    is_confident = False\n",
    "\n",
    "                examples = adj_examples.get(lemma, {\"Affect\":[], \"Judgement\":[], \"Appreciation\":[], \"ambiguous\":[]})\n",
    "                ex_aff = \" || \".join(examples[\"Affect\"])\n",
    "                ex_jud = \" || \".join(examples[\"Judgement\"])\n",
    "                ex_app = \" || \".join(examples[\"Appreciation\"])\n",
    "                ex_amb = \" || \".join(examples[\"ambiguous\"])\n",
    "                if round(max_prob, 4) > confidence_threshold:\n",
    "                    rows.append({\n",
    "                        \"language\": lang,\n",
    "                        \"Domain\": Domain,\n",
    "                        \"adjective\": lemma,\n",
    "                        \"total_count\": tot,\n",
    "                        \"Affect_count\": aff,\n",
    "                        \"Judgement_count\": jud,\n",
    "                        \"Appreciation_count\": app,\n",
    "                        \"ambiguous_count\": amb,\n",
    "                        \"p_Affect\": round(p_aff, 4),\n",
    "                        \"p_Judgement\": round(p_jud, 4),\n",
    "                        \"p_Appreciation\": round(p_app, 4),\n",
    "                        \"assigned_class\": assigned_class,\n",
    "                        \"assigned_confidence\": round(max_prob, 4),\n",
    "                        \"example_Affect\": ex_aff,\n",
    "                        \"example_Judgement\": ex_jud,\n",
    "                        \"example_Appreciation\": ex_app,\n",
    "                        \"example_ambiguous\": ex_amb\n",
    "                    })\n",
    "\n",
    "            rows = sorted(rows, key=lambda r: r[\"total_count\"], reverse=True)\n",
    "            if top_n:\n",
    "                rows = rows[:top_n]\n",
    "            all_rows.extend(rows)\n",
    "    return all_rows\n",
    "\n",
    "# ---------- run ----------\n",
    "def main(threshold=CONFIDENCE_THRESHOLD):\n",
    "    out = compute_appraisal_with_examples_by_class(CONLLU_ROOT, top_n=KEEP_TOP_N, lang_filter=\"en\", confidence_threshold=threshold)\n",
    "    if not out:\n",
    "        print(\"No results (check your CONLLU_ROOT path and folder structure).\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "    with open(OUT_CSV, \"w\", encoding=\"utf-8\", newline=\"\") as fh:\n",
    "        writer = csv.DictWriter(fh, fieldnames=list(out[0].keys()))\n",
    "        writer.writeheader()\n",
    "        for row in out:\n",
    "            writer.writerow(row)\n",
    "    print(\"Saved:\", OUT_CSV)\n",
    "    print(f\"Used confidence threshold = {threshold}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91377b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
